{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND4hWA19O8oDIpP1N6pgGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/AgenticAI/blob/main/11_LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph\n",
        "\n",
        "* https://langchain-ai.github.io/langgraph/\n",
        "* https://langchain-ai.github.io/langgraph/#langgraphs-ecosystem\n",
        "* LangGraph\n",
        "* LangGraph Studio\n",
        "* LangGraph Platform\n"
      ],
      "metadata": {
        "id": "5kAFp9vqGQHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agentic Design Patterns\n",
        "\n",
        "* Anthropic Building Effective Agents - https://www.anthropic.com/engineering/building-effective-agents  "
      ],
      "metadata": {
        "id": "Ar41hg5aIUSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Graphs\n",
        "\n",
        "### Core Concepts of Knowledge Graphs\n",
        "\n",
        "* **Nodes**: Represent individual entities (people, places, things) and are the fundamental units of information.\n",
        "* **Edges** (or **Relationships**): Connect nodes and define the associations between them (e.g., \"works for,\" \"is located in\").\n",
        "* **Triples**: The basic building block, forming a subject-predicate-object statement by connecting two nodes with an edge.\n",
        "* **Entities**: The individual things or concepts represented in the graph.\n",
        "* **Relationships**: Describe how entities are connected.\n",
        "* **Ontologies**: Provide a schema or structure for the graph, defining the types of entities and relationships that exist.\n",
        "* **Inference**: The process of using rules to deduce new facts based on existing knowledge within the graph.\n",
        "* **Context**: Provided by linking data together with semantic information, aiding in understanding the meaning and relationships.\n",
        "\n",
        "\n",
        "### Related Terms and Technologies\n",
        "\n",
        "* **Semantic Data Modeling**: The methodology used to represent the meaning and relationships between data points, making them machine-understandable.\n",
        "* **Data Ingestion**: The process of gathering and integrating data from various sources into the knowledge graph.\n",
        "* **Resource Description Framework (RDF)**: A standard model for representing information in knowledge graphs using subject-predicate-object triples.\n",
        "* **SPARQL**: A specific query language designed for retrieving and manipulating data from RDF graphs.\n",
        "* **Graph Theory**: The mathematical framework that knowledge graphs draw from for understanding and analyzing networks of interconnected nodes.\n",
        "* **Knowledge Base**: A general term; knowledge graphs are a type of knowledge base containing structured information for reasoning and decision-making.\n",
        "\n",
        "These concepts collectively allow knowledge graphs to represent complex relationships and support applications like search and AI systems.\n"
      ],
      "metadata": {
        "id": "ol2ZacIoKDeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Knowledge Base"
      ],
      "metadata": {
        "id": "4DEhYGfUKxkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph Databases"
      ],
      "metadata": {
        "id": "f9BbhLM5KNQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangGraph Terminology\n",
        "\n",
        "https://langchain-ai.github.io/langgraph/concepts/low_level/\n",
        "\n",
        "* State\n",
        "* Nodes\n",
        "* Edges"
      ],
      "metadata": {
        "id": "6ai4dU_sK9Y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangGraph Process\n",
        "\n",
        "* Define the State class\n",
        "* Start the Graph Builder\n",
        "* Create a Node\n",
        "* Create Edges\n",
        "* Compile the Graph"
      ],
      "metadata": {
        "id": "LgZEAZJyMEcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started"
      ],
      "metadata": {
        "id": "fqnrEaqT_56W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Image, display\n",
        "import gradio as gr\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel\n",
        "import random\n"
      ],
      "metadata": {
        "id": "c_jzT1mDBYt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv(override=True)"
      ],
      "metadata": {
        "id": "wHfKUsY1Bkz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some useful constants\n",
        "\n",
        "nouns = [\"Cabbages\", \"Unicorns\", \"Toasters\", \"Penguins\", \"Bananas\", \"Zombies\", \"Rainbows\", \"Eels\", \"Pickles\", \"Muffins\"]\n",
        "adjectives = [\"outrageous\", \"smelly\", \"pedantic\", \"existential\", \"moody\", \"sparkly\", \"untrustworthy\", \"sarcastic\", \"squishy\", \"haunted\"]"
      ],
      "metadata": {
        "id": "s2T4qTczBe0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### State Object\n",
        "\n",
        "* Dict (TypedDict)\n",
        "* Pydantic BaseModel"
      ],
      "metadata": {
        "id": "IQOtmq9aAbdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type Hinting"
      ],
      "metadata": {
        "id": "PcXPhRT0AjMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangGraph's Annotated"
      ],
      "metadata": {
        "id": "UH1RzYoYAAaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shout(text: Annotated[str, \"Something to shout about\"]) -> str:\n",
        "  print(text.upper())\n",
        "  return text.upper()"
      ],
      "metadata": {
        "id": "PuMoTQEyBuLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reducer\n",
        "\n",
        "* Hadoop's Map-Reduce?"
      ],
      "metadata": {
        "id": "K1J7fa2KATDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Define the State Object with Pydantic BaseModel"
      ],
      "metadata": {
        "id": "fgxeOzrzCBhk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs_6FOhSMZK5"
      },
      "outputs": [],
      "source": [
        "class State(BaseModel):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Start the Graph Builder"
      ],
      "metadata": {
        "id": "ElHaXPETCOP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "X4OPzlf8CVeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a Node"
      ],
      "metadata": {
        "id": "DIXX_ca6Cbhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def our_first_node(old_state: State) => State:\n",
        "  reply = f\"{random.choice(nouns)} are {random.choice(adjectives)}\"\n",
        "  messages = [{\"role\": \"assistant\", \"content\": reply}]\n",
        "  new_state = State(messages=messsages)\n",
        "  return new_state\n",
        "\n",
        "graph_builder.add_node(\"first_node\", our_first_node)"
      ],
      "metadata": {
        "id": "Kpboj4QoCUc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Create Edges"
      ],
      "metadata": {
        "id": "QPME-cwyDGdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START, \"first_node\")\n",
        "graph_builder.add_edge(\"first_node\", END)"
      ],
      "metadata": {
        "id": "fY2P1CT0DJcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Compile the Graph"
      ],
      "metadata": {
        "id": "rYqC69HSDVnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()\n",
        "display(Image(graph.get_graph().draw_mermaild_png()))"
      ],
      "metadata": {
        "id": "4PyrCXJODqFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Implementation"
      ],
      "metadata": {
        "id": "I5bmXlyBDw1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(user_input: str, history):\n",
        "    message = {\"role\": \"user\", \"content\": user_input}\n",
        "    messages = [message]\n",
        "    state = State(messages=messages)\n",
        "    result = graph.invoke(state)\n",
        "    print(result)\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "id": "l2QTyEgDD3sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the State object\n",
        "class State(BaseModel):\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "bLa-AX5_D__n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Start the Graph Builder with this State class\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "9V_Rc-FWEA3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create a Node\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "def chatbot_node(old_state: State) -> State:\n",
        "    response = llm.invoke(old_state.messages)\n",
        "    new_state = State(messages=[response])\n",
        "    return new_state\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot_node)"
      ],
      "metadata": {
        "id": "qjTZ6Em4EDa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create Edges\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)"
      ],
      "metadata": {
        "id": "1XFWRLQGELdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Compile the Graph\n",
        "graph = graph_builder.compile()\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "QUnIM0LMEOVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(user_input: str, history):\n",
        "    initial_state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
        "    result = graph.invoke(initial_state)\n",
        "    print(result)\n",
        "    return result['messages'][-1].content\n",
        "\n",
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "id": "Jm-9M3ArETT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory"
      ],
      "metadata": {
        "id": "7ePbZxW6EXjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from langgraph.graph import StateGraph, START\n",
        "from langgraph.graph.message import add_messages\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import Image, display\n",
        "import gradio as gr\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "import requests\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import TypedDict\n",
        "\n",
        "load_dotenv(override=True)"
      ],
      "metadata": {
        "id": "FWrkM3PpPFv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Super Step\n",
        "\n",
        "A super-step in LangGraph is a single, discrete, and transactional unit of execution within a graph. All active nodes within a super-step execute concurrently, and their combined state updates are applied atomically, meaning either all updates succeed or none do, ensuring state consistency.\n",
        "\n",
        "A super-step can be considered a single iteration over the graph nodes. Nodes that run in parallel are part of the same super-step, while nodes that run sequentially belong to separate super-steps."
      ],
      "metadata": {
        "id": "T-BXWr2zJ8hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangSmith\n",
        "\n",
        "LangSmith is a unified platform developed by LangChain for **debugging, testing, evaluating, and monitoring** applications built with large language models (LLMs).\n",
        "\n",
        "Essentially, it provides the necessary tools to take your LLM prototypes (often built with frameworks like LangChain or LangGraph) and make them production-ready and reliable.\n",
        "\n",
        "Key aspects of LangSmith include:\n",
        "\n",
        "* **Observability (Tracing):** It allows you to visualize and understand the step-by-step execution of your LLM applications, including prompts, responses, tool calls, and intermediate steps. This is crucial for debugging the non-deterministic nature of LLMs.\n",
        "* **Evaluation:** LangSmith helps you assess the performance and quality of your LLM applications. You can create datasets, run experiments, and use various evaluators (including LLM-as-a-Judge or custom ones) to score application performance and gather human feedback.\n",
        "* **Prompt Engineering:** It provides tools like a Playground to iterate on prompts, compare different versions, and collaborate with your team to find the most effective prompts.\n",
        "* **Monitoring:** You can track key business metrics like costs, latency, and response quality in live dashboards, and set up alerts for issues in production.\n",
        "\n",
        "In short, while frameworks like LangChain help you **build** LLM applications, LangSmith helps you **ensure they work reliably and perform well** in real-world scenarios."
      ],
      "metadata": {
        "id": "BieIO0O7KCsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tools"
      ],
      "metadata": {
        "id": "qQVymB-DP8I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "\n",
        "serper = GoogleSerperAPIWrapper()\n",
        "serper.run(\"What is the capital of France?\")"
      ],
      "metadata": {
        "id": "veWd-r0JP02B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using LangChain Wrapper"
      ],
      "metadata": {
        "id": "Lw4gYuxGQjI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "tool_search =Tool(\n",
        "        name=\"search\",\n",
        "        func=serper.run,\n",
        "        description=\"Useful for when you need more information from an online search\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "NX9QUkSmP2uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Tool"
      ],
      "metadata": {
        "id": "_1W7n3hFJ8eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
        "# pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
        "# pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
        "\n",
        "def push(text: str):\n",
        "    \"\"\"Send a push notification to the user\"\"\"\n",
        "    # requests.post(pushover_url, data = {\"token\": pushover_token, \"user\": pushover_user, \"message\": text})\n",
        "    return text\n",
        "\n",
        "tool_push = Tool(\n",
        "        name=\"send_push_notification\",\n",
        "        func=push,\n",
        "        description=\"useful for when you want to send a push notification\"\n",
        "    )\n",
        "\n",
        "tool_push.invoke(\"Hello World!\")"
      ],
      "metadata": {
        "id": "UGxAfp2xKLDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [tool_search, tool_push]"
      ],
      "metadata": {
        "id": "JvD-fLYbQskj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the State object\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "4Zc6n4OURLJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Start the Graph Builder with this State class\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "1nbnZNguRIm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create a Node\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"tools\", ToolNode(tools=tools))"
      ],
      "metadata": {
        "id": "ygzkQWLiRemg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create Edges\n",
        "graph_builder.add_conditional_edges( \"chatbot\", tools_condition, \"tools\")\n",
        "\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "id": "SgmRKcKGRsko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Compile the Graph\n",
        "graph = graph_builder.compile()\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "zwkE1s7rR4PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interface"
      ],
      "metadata": {
        "id": "626pIrJdSE3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(user_input: str, history):\n",
        "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]})\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "\n",
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "id": "zU_7YNyRSDX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory"
      ],
      "metadata": {
        "id": "E6V8vNQXSH2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Steps 1 and 2\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Step 3\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    print(state)\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
        "\n",
        "# Step 4\n",
        "graph_builder.add_conditional_edges( \"chatbot\", tools_condition, \"tools\")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "# Step 5\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "xiYA43BTSeAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "def chat(user_input: str, history):\n",
        "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config=config)\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "\n",
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "id": "2FystK81Ss7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.get_state(config)"
      ],
      "metadata": {
        "id": "mqFikRuCSz4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Most recent first\n",
        "list(graph.get_state_history(config))"
      ],
      "metadata": {
        "id": "63rk-7bzS5Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "db_path = \"memory.db\"\n",
        "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
        "sql_memory = SqliteSaver(conn)\n",
        "\n",
        "# Steps 1 and 2\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Step 3\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    print(state)\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
        "\n",
        "# Step 4\n",
        "graph_builder.add_conditional_edges( \"chatbot\", tools_condition, \"tools\")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "# Step 5\n",
        "graph = graph_builder.compile(checkpointer=sql_memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "FYvQ9LeOTAmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
        "\n",
        "def chat(user_input: str, history):\n",
        "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config=config)\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "gr.ChatInterface(chat, type=\"messages\").launch()"
      ],
      "metadata": {
        "id": "o09nnr4uTMbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
